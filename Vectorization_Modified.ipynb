{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "onj = SentimentIntensityAnalyzer()\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import chardet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.3.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chardet in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (5.2.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk>=3.1->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk>=3.1->textblob) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk>=3.1->textblob) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk>=3.1->textblob) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk>=3.1->textblob) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from vaderSentiment) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->vaderSentiment) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->vaderSentiment) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->vaderSentiment) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->vaderSentiment) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.26.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\harsh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = [\n",
    "    \"gameofthrones\",\n",
    "    \"aww\",\n",
    "    \"gaming\",\n",
    "    \"news\",\n",
    "    \"politics\",\n",
    "    \"dankmemes\",\n",
    "    \"relationship_advice\",\n",
    "    \"nba\",\n",
    "    \"worldnews\",\n",
    "    \"AskReddit\",\n",
    "    \"AmItheAsshole\",\n",
    "    \"SquaredCircle\",\n",
    "    \"The_Donald\",\n",
    "    \"leagueoflegends\",\n",
    "    \"hockey\",\n",
    "    \"videos\",\n",
    "    \"teenagers\",\n",
    "    \"gonewild\",\n",
    "    \"movies\",\n",
    "    \"funny\",\n",
    "    \"pics\",\n",
    "    \"marvelstudios\",\n",
    "    \"memes\",\n",
    "    \"soccer\",\n",
    "    \"freefolk\",\n",
    "    \"MortalKombat\",\n",
    "    \"todayilearned\",\n",
    "    \"apexlegends\",\n",
    "    \"asoiaf\",\n",
    "    \"Market76\",\n",
    "    \"Animemes\",\n",
    "    \"FortNiteBR\",\n",
    "    \"nfl\",\n",
    "    \"trashy\",\n",
    "    \"unpopularopinion\",\n",
    "    \"ChapoTrapHouse\",\n",
    "    \"RoastMe\",\n",
    "    \"Showerthoughts\",\n",
    "    \"wallstreetbets\",\n",
    "    \"Pikab\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_dict = {subreddit[i]:i for i in range(len(subreddit))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        result = chardet.detect(file.read())\n",
    "    return result['encoding']\n",
    "\n",
    "file_path = 'pre-processed-data.csv'\n",
    "detected_encoding = detect_encoding(file_path)\n",
    "\n",
    "df = pd.read_csv(file_path, encoding=detected_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.drop(columns=['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df -->train and test\n",
    "below --?train data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (800000,) (800000,)\n",
      "Test set shape: (200001,) (200001,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['0']\n",
    "X = df['body']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([y_train,X_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[0]['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = {'Subjectivity':[],'Polarity':[],'Neg':[],'Pos':[],'Compound':[],'Complexity':[],'Class':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Subjectivity': [],\n",
       " 'Polarity': [],\n",
       " 'Neg': [],\n",
       " 'Pos': [],\n",
       " 'Compound': [],\n",
       " 'Complexity': [],\n",
       " 'Class': []}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllables(word):\n",
    "    word = word.lower().strip()\n",
    "    vowel_sounds = re.findall(r'[aeiouy]+', word)\n",
    "    syllables = len(vowel_sounds)\n",
    "    if word.endswith('e'):\n",
    "        syllables -= 1\n",
    "    if word.endswith('y') and not re.match(r'[aeiouy]+y$', word):\n",
    "        syllables += 1\n",
    "    return syllables\n",
    "\n",
    "def flesch_kincaid_grade_level(text):\n",
    "    words = text.split()\n",
    "    sentences = re.split(r'[.?!]+', text.strip())\n",
    "\n",
    "    avg_syllables = sum(count_syllables(word) for word in words) / len(words)\n",
    "    avg_words_per_sentence = len(words) / len(sentences)\n",
    "\n",
    "    fkgl = 0.39 * avg_words_per_sentence + 11.8 * avg_syllables - 15.59\n",
    "    return round(fkgl, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         17\n",
       "body    love\n",
       "Name: 382311, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_11692\\1005280258.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_data['Class'].append(df_train.iloc[i][0])\n"
     ]
    }
   ],
   "source": [
    "for i in range(df_train.shape[0]):\n",
    "    text = str(df_train.iloc[i]['body'])\n",
    "    blob = TextBlob(text)\n",
    "    df_data['Subjectivity'].append(blob.subjectivity)\n",
    "    df_data['Polarity'].append(blob.sentiment.polarity)\n",
    "    polarity_scores = onj.polarity_scores(text)\n",
    "    df_data['Neg'].append(polarity_scores['neg'])\n",
    "    df_data['Pos'].append(polarity_scores['pos'])\n",
    "    df_data['Compound'].append(polarity_scores['compound'])\n",
    "    fkgl = flesch_kincaid_grade_level(text)\n",
    "    df_data['Complexity'].append(fkgl)\n",
    "    df_data['Class'].append(df_train.iloc[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_train = pd.DataFrame(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Neg</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Complexity</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>-3.40</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>2.88</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.89</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>-0.44375</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>1.29</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subjectivity  Polarity    Neg   Pos  Compound  Complexity  Class\n",
       "0      0.600000   0.50000  0.000  1.00    0.6369       -3.40     17\n",
       "1      0.500000   0.50000  0.000  0.42    0.4404        2.88     19\n",
       "2      0.000000   0.00000  0.000  0.00    0.0000        2.89     27\n",
       "3      0.583333  -0.44375  0.233  0.30    0.0018        1.29     26\n",
       "4      0.000000   0.00000  0.000  0.00    0.0000        7.60      3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_train.to_csv('Mid_data_train.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Mid_data_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.iloc[:,:6]\n",
    "labels = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_medians = features.groupby(labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_params(text):\n",
    "    blob = TextBlob(text)\n",
    "    polarity_scores = onj.polarity_scores(text)\n",
    "    fkgl = flesch_kincaid_grade_level(text)\n",
    "    return [blob.subjectivity,blob.sentiment.polarity,polarity_scores['neg'],polarity_scores['pos'],polarity_scores['compound'],fkgl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(data_point1, data_point2):\n",
    "    dot_product = np.dot(data_point1, data_point2)\n",
    "    norm1 = np.linalg.norm(data_point1)\n",
    "    norm2 = np.linalg.norm(data_point2)\n",
    "    similarity = dot_product / (norm1 * norm2)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([y_test,X_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>624589</th>\n",
       "      <td>32</td>\n",
       "      <td>pff example ferrell listed 35 said *ferrell ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79954</th>\n",
       "      <td>35</td>\n",
       "      <td>started work 99 boomer younger asshole vigor b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567130</th>\n",
       "      <td>29</td>\n",
       "      <td>combination following aae pump action shotgun ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500891</th>\n",
       "      <td>8</td>\n",
       "      <td>compare pharma marketing budget r &amp;amp;d, comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55399</th>\n",
       "      <td>8</td>\n",
       "      <td>wasn 't illegitimate election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639297</th>\n",
       "      <td>31</td>\n",
       "      <td>kevin *thoroughly* disliked cousin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311939</th>\n",
       "      <td>24</td>\n",
       "      <td>way saw wa wa waiting climb drogon \"bran\" like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324459</th>\n",
       "      <td>21</td>\n",
       "      <td>friend mentioned idea black widow movie end cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390499</th>\n",
       "      <td>24</td>\n",
       "      <td>actually 15 probably 14 filming scene **bella ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566853</th>\n",
       "      <td>2</td>\n",
       "      <td>agree completely better yes fun fairly connect...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200001 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                               body\n",
       "624589  32  pff example ferrell listed 35 said *ferrell ra...\n",
       "79954   35  started work 99 boomer younger asshole vigor b...\n",
       "567130  29  combination following aae pump action shotgun ...\n",
       "500891   8  compare pharma marketing budget r &amp;d, comp...\n",
       "55399    8                      wasn 't illegitimate election\n",
       "...     ..                                                ...\n",
       "639297  31                 kevin *thoroughly* disliked cousin\n",
       "311939  24  way saw wa wa waiting climb drogon \"bran\" like...\n",
       "324459  21  friend mentioned idea black widow movie end cr...\n",
       "390499  24  actually 15 probably 14 filming scene **bella ...\n",
       "566853   2  agree completely better yes fun fairly connect...\n",
       "\n",
       "[200001 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_point = []\n",
    "for i in range(df_test.shape[0]):\n",
    "    test_text = str(df_test.iloc[i]['body'])\n",
    "    test_data_point.append(return_params(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_11692\\1848760392.py:5: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  similarity = dot_product / (norm1 * norm2)\n"
     ]
    }
   ],
   "source": [
    "list_sim = []\n",
    "for j in range(len(test_data_point)):\n",
    "    similarity = {}\n",
    "    for i in range(class_medians.shape[0]):\n",
    "        similarity[i] = cosine_similarity(test_data_point[j],list(class_medians.iloc[i]))\n",
    "    list_sim.append(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_elements = []\n",
    "for i in range(len(list_sim)):\n",
    "    top_elements.append(list(list_sim[i].items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.9945848426909374),\n",
       " (1, 0.9899895007532584),\n",
       " (2, 0.9925434243530014),\n",
       " (3, 0.9951104386596537),\n",
       " (4, 0.9941171739023634),\n",
       " (5, 0.9919994519140726),\n",
       " (6, 0.9926167730479974),\n",
       " (7, 0.9932586442083119),\n",
       " (8, 0.9940587855846826),\n",
       " (9, 0.9935647040526497),\n",
       " (10, 0.9936378807484312),\n",
       " (11, 0.9928481613228304),\n",
       " (12, 0.994709058112989),\n",
       " (13, 0.9924803800988937),\n",
       " (14, 0.9936549435166017),\n",
       " (15, 0.9936677353342029),\n",
       " (16, 0.9927694044256955),\n",
       " (17, 0.9729587787852),\n",
       " (18, 0.9932738190536943),\n",
       " (19, 0.9935304505263797),\n",
       " (20, 0.9934150610230558),\n",
       " (21, 0.9930970213074652),\n",
       " (22, 0.9924921926175797),\n",
       " (23, 0.9931700503767211),\n",
       " (24, 0.9951157173867653),\n",
       " (25, 0.9932172594809789),\n",
       " (26, 0.9937413853964228),\n",
       " (27, 0.9936769849473188),\n",
       " (28, 0.9946563662497602),\n",
       " (29, 0.9894401508382134),\n",
       " (30, 0.9933763250914242),\n",
       " (31, 0.9930518993719555),\n",
       " (32, 0.9922989703652496),\n",
       " (33, 0.9947311079433254),\n",
       " (34, 0.9938438066400118),\n",
       " (35, 0.9942995496879816),\n",
       " (36, 0.9935436149483418),\n",
       " (37, 0.9928170327223272),\n",
       " (38, 0.9931672407075917),\n",
       " (39, -0.9921699213527637)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_elements[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for i in range(len(top_elements)):\n",
    "    max = top_elements[i][0][1]\n",
    "    min = top_elements[i][-1][1]\n",
    "    for j in range(len(top_elements[i])):\n",
    "        top_elements[i][j] = (top_elements[i][j][0],(top_elements[i][j][1]-min)/(max-min))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ishaan's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict={}\n",
    "\n",
    "with open(\"pre-processed-data_`.csv\", \"r\", encoding=\"utf8\", errors=\"ignore\") as f:\n",
    "\n",
    "    k=f.readline()\n",
    "\n",
    "    while(True):\n",
    "\n",
    "        k=f.readline()\n",
    "        \n",
    "        if len(k)==0:\n",
    "            break\n",
    "\n",
    "        _,x,k=k.split(\",\",2)\n",
    "\n",
    "        k=re.sub('[\\d|\\_]', '', k)\n",
    "\n",
    "        token_dict[x]=k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, stop_words='english')\n",
    "tfs = tfidf.fit_transform(token_dict.values())\n",
    "\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "dense=tfs.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names, index= list(token_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_lists = {i:subreddit[i] for i in range(len(subreddit))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_indices = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_indices = {i:i for i in list_indices}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_indices['Pikabu'] = 'Pikab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(index=list_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_matching_words(text,iter,top_elements):\n",
    "  text = re.sub('[\\d|\\_]','',text)\n",
    "  text = re.sub('[\\(|\\)|/]',' ',text)\n",
    "  out={}\n",
    "  for i in df.index:\n",
    "    out[i]=top_elements[iter][subreddit_dict[i]][1]**2\n",
    "    \n",
    "  for word in text.split():\n",
    "\n",
    "    if word not in df.columns:\n",
    "      continue\n",
    "      \n",
    "    for sub in df.index:\n",
    "\n",
    "      if df.loc[sub][word]>0:\n",
    "        out[sub]=out[sub]+(df.loc[sub][word])**0.5\n",
    "\n",
    "  out=dict(sorted(out.items(), reverse=True, key=lambda item:item[1]))\n",
    "  return list(out.keys())[0]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_predict_lists = []\n",
    "acc=0\n",
    "for i in X_test.index:\n",
    "    output_predict_lists.append(count_matching_words(str(X_test[i]),k,top_elements))\n",
    "    k+=1\n",
    "\n",
    "    if subreddit_lists[y_test[i]]==output_predict_lists[-1]:\n",
    "        acc+=1\n",
    "\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80203"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  40.10129949350254\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the model is: \",acc/len(X_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You dont need to add the next part, it is for further extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "\n",
    "def analyze_text(text):\n",
    "    \"\"\"\n",
    "    Analyzes a text and returns a dictionary containing values for 6 dimensions:\n",
    "        - joy\n",
    "        - anger\n",
    "        - complexity (average number of syllables per word)\n",
    "    \"\"\"\n",
    "    # Create a TextBlob object\n",
    "    blob = TextBlob(text)\n",
    "\n",
    "    # Calculate emotion scores (range: 0-1)\n",
    "    joy = blob.sentiment.polarity\n",
    "    anger = blob.sentiment.subjectivity\n",
    "\n",
    "    # Calculate word complexity (average syllables per word)\n",
    "    syllables = sum(count_syllables(word) for word in text.split())\n",
    "    word_count = len(text.split())\n",
    "    complexity = syllables / word_count if word_count else 0\n",
    "\n",
    "\n",
    "    # Return dictionary with analysis results\n",
    "    return {\n",
    "        \"joy\": joy,\n",
    "        \"anger\": anger,\n",
    "        \"complexity\": complexity,\n",
    "    }\n",
    "\n",
    "\n",
    "def count_syllables(word):\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    word = word.lower().strip()\n",
    "\n",
    "    # Count vowel sounds\n",
    "    vowel_sounds = re.findall(r\"[aeiouy]+\", word)\n",
    "\n",
    "    # Count syllables (assume consonant sounds between vowel sounds)\n",
    "    syllables = len(vowel_sounds)\n",
    "\n",
    "    # Special cases for silent \"e\" and \"y\"\n",
    "    if word.endswith(\"e\"):\n",
    "        syllables -= 1\n",
    "    if word.endswith(\"y\") and not re.match(r\"[aeiouy]+y$\", word):\n",
    "        syllables += 1\n",
    "\n",
    "    return syllables\n",
    "\n",
    "\n",
    "def flesch_kincaid_grade_level(text):\n",
    "\n",
    "    words = text.split()\n",
    "    sentences = re.split(r\"[.?!]+\", text.strip())\n",
    "\n",
    "    avg_syllables = sum(count_syllables(word) for word in words) / len(words)\n",
    "    avg_words_per_sentence = len(words) / len(sentences)\n",
    "\n",
    "    fkgl = 0.39 * avg_words_per_sentence + 11.8 * avg_syllables - 15.59\n",
    "\n",
    "    return round(fkgl, 2)\n",
    "\n",
    "text = \"Supercalifragilisticexpialidocious\"\n",
    "analysis_data = analyze_text(text)\n",
    "\n",
    "print(analysis_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
